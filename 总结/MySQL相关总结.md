# MySQL进阶总结

## 一.MySQL的存储引擎的区别

### 1.InnoDB和MyISAM

MyISAM使用的是非聚簇索引**，索引与数据分开存储**，索引文件中记录了数据的指针；不支持事务；表锁；支持全文索引。适合大量的select，不适合大量的update。

InnoDB：默认为聚簇索引，支持事务，提供行锁，支持外键，5.6版本后支持全文索引

MySQL为什么使用InnoDB

支持事务，聚簇索引，支持外键，MVCC

MySQL索引结构

B+树，B+树可以对叶子结点顺序查找，因为叶子结点存放了数据结点且有序

b树是一个多路平衡搜索树，插入时，如果超过阶数就会以中间元素进行向上分裂；其中数据存储在每一个结点中。每个结点是一页，当数据存放在节点中，导致页中存储的键值减少，要保留大量数据时，树的高度就会增加，导致性能降低。

b+树的所有结点数据都会出现在叶子节点中，非叶子结点主要起到索引的作用，之后每个结点中间通过指针进行连接，形成双向链表，方便了范围搜索和排序。

哈希索引：不支持范围查找，不支持排序操作，只支持等值操作。

主键索引和普通索引的区别

主键索引的叶子结点存放了整行记录，普通索引的叶子结点存放了数据主键ID，查询的时候需要做一次回表查询（如果查询字段刚好是索引字段或时索引的一部分，就不用回表（索引覆盖原理））



## 二.索引分类

### **1.聚簇索引（主键索引,primary）**

聚簇索引：将数据和索引放在了一块，索引结构的叶子结点保存了行数据，必须有，只能有一个。

MySQL是根据主键顺序存放数据，聚簇索引就是根据每张表的主键来构造一棵B+树，叶子结点存放整张表的行数据；由于表中数据只能按照一棵B+树排序，所以1张表中只能有一个聚簇索引。

使用规则，主键索引默认为聚簇索引；如果没有主键，使用uinque；都没有InnoDB会隐式定义一个rowid作为聚簇索引

### 2.非聚簇索引（二级索引)

非聚簇索引：数据与索引分开存储，索引结构的叶子结点关联的是对应的主键，可以有多个。

#### （1）联合索引

创建时考虑顺序（最左匹配原则）

多个列字段建立的索引，要满足最左匹配原则，并且遇到范围查询时（>,<,between, like）就会停止匹配，

index(a,b)，查b=2,不会使用索引，不符合最左匹配。

如 index(a,b,c,d)，查a=1 and b=2 and c<10 and d=5，只有a,b,c可以使用到联合索引。

将c<10改为c<=10就可以避免索引失效。

如果存在多个查询条件，考虑建立联合索引（不使用单列索引的原因是，如果多个单列同时查找，mysql会选择其中效率高的一个）

#### （2）前缀索引

当索引字段较长，匹配很慢时，可以使用索引部分字段进行匹配，提高索引效率。

如，学号较长，且前面重复数字较多，可以使用后面不重复的项作为索引

create index 索引名 on 表名 (索引列（前几个字符）)。

前缀长度：根据索引的选择性来决定，选择性指不重复的索引值和数据表的记录总数比值，索引选择性越高，则查询效率越高。唯一索引的选择性为1，最好的索引选择性，效率最高

计算公式：select count(distinct substring(phone,1,7))/count(0)  from user;计算截取字符串的选择性，选取需要的即可。 

#### **（3）普通索引**

普通索引的叶子结点存放的是主键值，先在普通索引建立的B+树中查找到主键值，然后再在主键索引的B+树中查找的指定的值（回表操作）。如果需要查询的值在普通索引上，直接返回，不用进行回表，将该操作也成为**覆盖索引，由于减少了树的搜索次数，提高了查询效率，也是一个性能优化手段**。

#### **（4）唯一索引**

与普通索引类似，只不过索引列的值唯一，可以为空(unique)

#### **（5）全文索引**

MySQL允许在char，varchar,和text上建立全文索引，查找的是文本中的关键字（fulltext）

#### （6）索引失效

在索引列上进行运算操作，索引就会失效；

联合索引不符合最佐匹配也会失效；

字符串类型不加引号，索引会失效

使用like进行头部模糊匹配索引失效（尾部模糊不会）

使用or条件连接时，如果有一个条件没有索引，整个索引就会失效；

数据分布影响，如果大多数数据需要查询，mysql评估使用索引比全表慢，则不使用索引

#### （7)覆盖索引

查询使用到了索引，并且需要返回的列在该索引中已经全部找到，减少select *的使用，在select中的字段尽量是二级索引中的字段，避免了回表操作。

### 3.索引设计原则

对于数据量较大，查询比较频繁的表建立索引

对于常作为查询条件的 where,order by, group by 操作的字段建立索引

选择区分度高的列建立索引，尽量建立唯一索引

如果为字符串类型的字段，且较长时，可以根据字段特点，建立前缀索引

尽量使用联合索引，大多数可以覆盖索引，避免回表

控制索引的数量，不能过多，过多影响增删改的效率

如果索引列不为null,建表时进行非空约束。因为优化器知道每列是否为null时，可以更好地确定哪个索引最有效地用于查询（方便优化器进行优化查询）



### 4.创建索引的方式

创建普通索引的语句

create index 索引名 on 表名 （建立索引的字段（长度）），在text/blob类型时，必须指定长度

alter table 表名 add index 索引名(列名)

删除索引

drop index 索引名 on 表名

创建唯一性索引

create unique index 索引名 on 表名 （建立索引的列名）

alter table 表名 add unique 索引名(列名)



### 5.SQL性能分析

1.索引相关

#### （1）查看sql的执行频率（包含增删改查）

通过show [session,global] status like 'COM_' （其中一个下划线代表一个字符，session代表当前会话，glogal代表全局的执行频率） ；主要优化的是查询。

#### （2）慢查询日志分析（找哪些sql执行效率低）

如果某种查询的执行时间超过了默认的10s，就会将该查询sql记录在慢查询日志中。

慢查询日志默认是关闭的。需要在mysql中配置文件my.cnf中进行配置，

slow_query_log=1，开启慢查询日志；long_query_time=2,设置慢日志的时间，超过该时间就认为是慢查询，记录慢查询日志

在Linux的var/lib/mysql/localhost-slow.log中记录慢查询的日志信息。

#### （3）profile详情

show profiles 可以了解到时间都耗费到哪里了。

select @@have_profiling;查看是否支持profile功能；

set profiling=1；设置开启该开关

(4)explain执行计划分析

主要通过type,possible_key, key, key_len，extra来判断如何进行优化

#### （5）sql提示

优化数据库的一种手段，就是在sql中添加一些人为提示来达到优化操作的目的。

在from表名后跟上该关键字

use index（索引名）: 告诉数据库使用哪个索引（只是个建议）

ignore index（）：不使用哪个索引

force index() :告诉数据库必须走该索引



### 6.SQL语句优化

#### （1）插入数据

批量插入（500-1000），手动提交事务（多个insert前后开启事务），主键顺序插入；

大批量插入数据使用load指令进行插入（本地文件数据加载到数据库中）

load使用：

1.客户端连接加上参数 --local-infile

mysql -u --local-infile -u root -p

2.设置全局参数local_infile=1

set glaoble local_infile=1;

3.执行load指令加载文件数据到数据库表中

load data local infile '文件路径及文件名.log' into table 表名 fields terminated by '分隔符，' lines  terminated by '换行符\n'；

#### （2）主键优化

1.按照主键有序插入，可以选择主键自增

sql空间分布，段-区-页-行；如果是主键乱序插入，会产生页分裂，中间还要维护指针；在删除的时候会产生页合并（默认50%会操作，自动会进行）

2.降低主键长度

3.避免使用uuid或自然主键，如身份证做主键（因为无序）

4.尽量避免对主键进行修改

#### （3）order by 优化

1.using filesort 性能低，不是通过索引直接返回排序结果的排序。

2.using index 是尽量优化到该层面，通过有序索引顺序扫描直接返回有序数据，不需要额外排序

优化为using index层面主要是对需要排序的字段建立索引（使用联合索引时，两个都应为升序或降序；如果两个不同，就会出现filesort，解决方式：可以建立索引指定排序方式），尽量使用覆盖索引，避免使用select *。

如果无法避免filesort就增大排序缓冲区。

#### （4）group by 优化

分组操作时可以建立索引来提高效率；分组操作时索引也满足最左前缀法则；在where和group by 连起来也是联合索引。

#### （5）limit 优化

limit越往后分页查询效率越低；通过覆盖索引+子查询的形式进行优化。

通过子查询查找到满足分页数据的主键id，然后再根据这些id查找需要的字段。

#### （6）count 优化

自己计数，在redis使用插入或删除进行计数操作，比较麻烦。使用count（*）效率稍高，数据库做了优化。

count用法，对于非null的就累计加1

#### （7）update优化

更新数据的时候根据索引进行更新，开启事务后，where后有索引的更新是行锁（根据索引进行加锁），没有索引的更新是表锁。



## 三.锁机制

### 1.全局锁

锁定数据库中所有的表，加锁后整个实例处于只读状态，已经更新操作的事务提交语句都会被阻塞。

应用场景：全库的逻辑备份，保证数据的完整性（没有锁会导致数据一致性问题），通过mysqldump用于数据库备份。

加锁：flush tables with read lock;

备份命令:mysqldump -h 远程sql主机地址（ip）  -uroot -p密码  备份的数据库名>备份名.sql

解锁：unlock tables;

缺点：如果在主库上备份，备份期间不能更新，导致业务停摆；如果在从库备份，备份期间从库不能执行主库同步过来的二进制文件，导致主从延迟。

解决方法：在InnooDB中，在备份时，加上 --single-transaction 参数完成不加锁的一致性数据备份（底层通过快照读进行实现）。

### 2.表级锁

每次操作锁住整个表，锁粒度大，锁冲突概率高。

#### （1）表锁

**表共享读锁**：所有客户端只能进行读，不能进行写。

**表独占写锁**：本客户端可以读写，其他客户端不能读写。

加锁：lock tables 表名  read/write

释放锁：unlock tables  或者客户端断开连接

#### （2）元数据锁（MDL，读锁，共享锁）

MDL加锁是系统自动控制，在当前表未提交事务时，修改表结构时不可以对元数据进行写操作。

主要避免DML（增删改查相关）与DDL（表结构相关）的冲突，保证读写的正确性

增删查改时会自动加上MDL读锁（共享），在使用alter修改表结构时，会加上MDL写锁（排他）

当前事务未提交时，其他端口的数据库可以对该表进行读写，当其他端口的数据库对未提交事务的表使用alert进行修改表结构就会发生阻塞。

#### （3）意向锁

主要解决行锁和表锁冲突问题。

没有意向锁前，在一个事务中修改一条数据，会对该行数据加一个行锁，如果另一个客户端对该表加表锁前，会逐行检查当前是否可以加表锁，效率低，所以有了意向锁减少表锁的检查。

在加行锁后再加一个意向锁，之后加表锁前检查是否与当前意向锁是否兼容冲突，如果不兼容，直到之前的事务提交，释放了行锁和意向锁之后才可以加表锁。

意向共享锁：由select ... lock in share mode 进行添加；与表锁共享锁(read)兼容，与表锁排他锁（write）互斥。

意向排他锁：由insert,update,delete,select ... for update添加；与表锁共享锁和表排他锁互斥，意向锁之间不会互斥。

## 3.行级锁

每次操作锁定对应的行数据，因为innoDB数据是基于索引组织，所以行锁通过索引上的索引项加锁实现

#### （1）行锁

锁定单行记录的锁，防止其他事务对其进行update和delete，在读已提交和可重复读下都支持。

共享锁：允许一个事务去读一行，阻止其他事务获取相同数据集的排他锁。

排他锁：允许排他锁的事务更新数据，组织其他事务获得相同数据集的共享锁和排他锁。

总结：一个获取到共享锁，另一个也可以获取到共享锁，但是获取不到排他锁；一个获取到排他锁，另一个获取不到共享锁也获取不到排他锁。

#### （2）间隙锁

锁定索引记录间隙（不包含该记录），确保索引记录间隙不变，防止其他事务在这个间隙进行insert，产生幻读。在可重复读级别下都支持。只有事务提交后，锁也就释放了，另一个就可以进行操作。

间隙锁的目的是防止其他事务插入间隙（防止幻读），一个事务采用的间隙锁不会阻止另一个事务在同一间隙上采用间隙锁。

#### （3）临键锁

行锁和间隙锁的结合，同时锁住数据并锁住数据前面的间隙，在可重复读级别下支持。

![image-20220814182949350](C:\Users\hasee\AppData\Roaming\Typora\typora-user-images\image-20220814182949350.png)

![image-20220814183149728](C:\Users\hasee\AppData\Roaming\Typora\typora-user-images\image-20220814183149728.png)

![image-20220814184832600](C:\Users\hasee\AppData\Roaming\Typora\typora-user-images\image-20220814184832600.png)

![image-20220814190320807](C:\Users\hasee\AppData\Roaming\Typora\typora-user-images\image-20220814190320807.png)



## 四.事务相关

### 1.事务相关概念

![image-20220816114231063](C:\Users\hasee\AppData\Roaming\Typora\typora-user-images\image-20220816114231063.png)

### 2.事务原理

#### （1）每一个通过什么进行保证

![image-20220816114611936](C:\Users\hasee\AppData\Roaming\Typora\typora-user-images\image-20220816114611936.png)

#### （2）通过redo log 保证持久性

![image-20220816115454368](C:\Users\hasee\AppData\Roaming\Typora\typora-user-images\image-20220816115454368.png)

#### （3）undo log 保证原子性（事务回滚到之前的数据）

![image-20220816120000704](C:\Users\hasee\AppData\Roaming\Typora\typora-user-images\image-20220816120000704.png)



## 四.MVCC（多版本并发控制）

### 1.相关概念

![image-20220816120449530](C:\Users\hasee\AppData\Roaming\Typora\typora-user-images\image-20220816120449530.png)

### 2.MVCC实现原理

#### （1）三个隐式字段

事务ID（最后一次操作事务的ID），回滚指针，隐藏主键

![image-20220816121049084](C:\Users\hasee\AppData\Roaming\Typora\typora-user-images\image-20220816121049084.png)

#### （2）undo log 日志

![image-20220816122459931](C:\Users\hasee\AppData\Roaming\Typora\typora-user-images\image-20220816122459931.png)

#### （3）readView

通过undo log 版本链中生成的多个版本记录链表，具体读取哪一个，根据readView来决定。

![image-20220816123056528](C:\Users\hasee\AppData\Roaming\Typora\typora-user-images\image-20220816123056528.png)

![image-20220816123045600](C:\Users\hasee\AppData\Roaming\Typora\typora-user-images\image-20220816123045600.png)

具体匹配过程示例：

1读已提交过程

![image-20220816123750867](C:\Users\hasee\AppData\Roaming\Typora\typora-user-images\image-20220816123750867.png)

2.可重复读过程

![image-20220816124133482](C:\Users\hasee\AppData\Roaming\Typora\typora-user-images\image-20220816124133482.png)

### 3.总结

![image-20220816125152351](C:\Users\hasee\AppData\Roaming\Typora\typora-user-images\image-20220816125152351.png)